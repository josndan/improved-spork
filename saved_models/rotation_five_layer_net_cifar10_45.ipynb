{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecJIqJhvoDJ5","outputId":"cadd2d7a-fa6a-4b52-b123-d0d9ef9131d3","executionInfo":{"status":"ok","timestamp":1650468168870,"user_tz":240,"elapsed":1318,"user":{"displayName":"Joseph Daniel Selvaraaj","userId":"01267249207347429283"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/CS682/Research\n"]}],"source":["# UNCOMMENT IF USING COLAB VM\n","\n","# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# TODO: Enter the foldername in your Drive where you have saved the unzipped\n","# assignment folder, e.g. 'cs231n/assignments/assignment1/'\n","FOLDERNAME = \"CS682/Research\"\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","# This downloads the CIFAR-10 dataset to your Drive\n","# if it doesn't already exist.\n","# %cd /content/drive/My\\ Drive/$FOLDERNAME/cs682/datasets/\n","# !bash get_datasets.sh\n","%cd /content/drive/My\\ Drive/$FOLDERNAME\n","\n","#!pip install efficientnet_pytorch"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"8xxr7yWFoXta","executionInfo":{"status":"ok","timestamp":1650468176241,"user_tz":240,"elapsed":6278,"user":{"displayName":"Joseph Daniel Selvaraaj","userId":"01267249207347429283"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.utils.data import sampler\n","# from efficientnet_pytorch import EfficientNet\n","\n","import torchvision.datasets as dset\n","import torchvision.transforms as T\n","from torchvision import models\n","import matplotlib.pyplot as plt\n","\n","from torch.optim import lr_scheduler\n","\n","import numpy as np\n","import torch.nn.functional as F\n","import time\n","import copy"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bmAicwCooYWe","outputId":"505a8097-8c66-4092-d6b9-d7a3a5830fa7","executionInfo":{"status":"ok","timestamp":1650468176241,"user_tz":240,"elapsed":3,"user":{"displayName":"Joseph Daniel Selvaraaj","userId":"01267249207347429283"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["using device: cuda\n"]}],"source":["USE_GPU = True\n","\n","dtype = torch.half # we will be using float throughout this tutorial\n","\n","if USE_GPU and torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","# Constant to control how frequently we print train loss\n","print_every = 100\n","\n","print('using device:', device)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NnFBMJgboasT","outputId":"135fb178-114c-43b9-eb47-e78494183e22","executionInfo":{"status":"ok","timestamp":1650468189117,"user_tz":240,"elapsed":12878,"user":{"displayName":"Joseph Daniel Selvaraaj","userId":"01267249207347429283"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["NUM_TRAIN = 49000\n","BATCH_SIZE = 64\n","INPUT_SIZE = 32\n","\n","# The torchvision.transforms package provides tools for preprocessing data\n","# and for performing data augmentation; here we set up a transform to\n","# preprocess the data by subtracting the mean RGB value and dividing by the\n","# standard deviation of each RGB value; we've hardcoded the mean and std.\n","transform = T.Compose([\n","                T.ToTensor(),\n","                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","                # T.Resize(INPUT_SIZE)\n","            ])\n","\n","# We set up a Dataset object for each split (train / val / test); Datasets load\n","# training examples one at a time, so we wrap each Dataset in a DataLoader which\n","# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n","# training set into train and val sets by passing a Sampler object to the\n","# DataLoader telling how it should sample from the underlying Dataset.\n","cifar10_train = dset.CIFAR10('./cs682/datasets', train=True, download=True,\n","                             transform=transform)\n","loader_train = DataLoader(cifar10_train, batch_size=BATCH_SIZE, \n","                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n","\n","cifar10_val = dset.CIFAR10('./cs682/datasets', train=True, download=True,\n","                           transform=transform)\n","loader_val = DataLoader(cifar10_val, batch_size=BATCH_SIZE, \n","                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n","\n","cifar10_test = dset.CIFAR10('./cs682/datasets', train=False, download=True, \n","                            transform=transform)\n","loader_test = DataLoader(cifar10_test, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"rvYOg8Opofs-","executionInfo":{"status":"ok","timestamp":1650468189117,"user_tz":240,"elapsed":5,"user":{"displayName":"Joseph Daniel Selvaraaj","userId":"01267249207347429283"}}},"outputs":[],"source":["dataloaders = {'train':loader_train, 'val':loader_val,'test':loader_test}\n","dataset_sizes = { 'train': len(loader_train)*BATCH_SIZE, 'val': len(loader_val)*BATCH_SIZE,'test':len(loader_test)*BATCH_SIZE}"]},{"cell_type":"code","source":["USE_GPU = True\n","\n","dtype = torch.float32 # we will be using float throughout this tutorial\n","\n","if USE_GPU and torch.cuda.is_available():\n","    device = torch.device('cuda')"],"metadata":{"id":"fxsiyYhaJ7OT","executionInfo":{"status":"ok","timestamp":1650468189117,"user_tz":240,"elapsed":5,"user":{"displayName":"Joseph Daniel Selvaraaj","userId":"01267249207347429283"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def check_accuracy_part34(loader, model):\n","    if loader.dataset.train:\n","        print('Checking accuracy on validation set')\n","    else:\n","        print('Checking accuracy on test set')   \n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()  # set model to evaluation mode\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","            scores = model(x)\n","            _, preds = scores.max(1)\n","            num_correct += (preds == y).sum()\n","            num_samples += preds.size(0)\n","        acc = float(num_correct) / num_samples\n","        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n","        return acc"],"metadata":{"id":"radSK8ehJXXt","executionInfo":{"status":"ok","timestamp":1650468189117,"user_tz":240,"elapsed":4,"user":{"displayName":"Joseph Daniel Selvaraaj","userId":"01267249207347429283"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"id":"eYE7OwRtoiSF","executionInfo":{"status":"ok","timestamp":1650468189118,"user_tz":240,"elapsed":5,"user":{"displayName":"Joseph Daniel Selvaraaj","userId":"01267249207347429283"}}},"outputs":[],"source":["def train_part34(model, optimizer,scheduler, filename, epochs=10,print_every=100):\n","    \"\"\"\n","    Train a model on CIFAR-10 using the PyTorch Module API.\n","    \n","    Inputs:\n","    - model: A PyTorch Module giving the model to train.\n","    - optimizer: An Optimizer object we will use to train the model\n","    - epochs: (Optional) A Python integer giving the number of epochs to train for\n","    \n","    Returns: Nothing, but prints model accuracies during training.\n","    \"\"\"\n","    model = model.to(device=device)  # move the model parameters to CPU/GPU\n","    best_acc = float(\"-inf\")\n","    # train_loss = []\n","    # train_acc = []\n","    # val_loss = []\n","    # val_acc = []\n","    for e in range(epochs):\n","        for t, (x, y) in enumerate(dataloaders['train']):\n","            model.train()  # put model to training mode\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","\n","            scores = model(x)\n","            loss = F.cross_entropy(scores, y)\n","\n","            # Zero out all of the gradients for the variables which the optimizer\n","            # will update.\n","            optimizer.zero_grad()\n","\n","            # This is the backwards pass: compute the gradient of the loss with\n","            # respect to each  parameter of the model.\n","            loss.backward()\n","\n","            # Actually update the parameters of the model using the gradients\n","            # computed by the backwards pass.\n","            optimizer.step()\n","\n","            if t % print_every == 0:\n","                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","                # train_loss.append(loss.item())\n","                acc = check_accuracy_part34(dataloaders['val'], model)\n","                if acc > best_acc:\n","                  best_acc = acc\n","                  torch.save(model.state_dict(), filename)\n","\n","                print()\n","        scheduler.step()"]},{"cell_type":"code","source":["def flatten(x):\n","    N = x.shape[0] # read in N, C, H, W\n","    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n","\n","class Flatten(nn.Module):\n","    def forward(self, x):\n","        return flatten(x)"],"metadata":{"id":"QrAgAAsZKGHJ","executionInfo":{"status":"ok","timestamp":1650468189118,"user_tz":240,"elapsed":5,"user":{"displayName":"Joseph Daniel Selvaraaj","userId":"01267249207347429283"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":19,"metadata":{"id":"EGTgE3B-oraB","executionInfo":{"status":"ok","timestamp":1650468346866,"user_tz":240,"elapsed":297,"user":{"displayName":"Joseph Daniel Selvaraaj","userId":"01267249207347429283"}}},"outputs":[],"source":["rotation_net = None\n","\n","channel_1 = 32\n","channel_2 = 16\n","channel_4 = 16\n","channel_5 = 10\n","hidden_layer_size = 200\n","num_classes = 4\n","num_classes_downstream = 10\n","\n","H1 = 1 + (32 + 2 * 2 - 5)\n","W1 = 1 + (32 + 2 * 2 - 5)\n","H2 = 1 + (H1 + 2 * 2 - 5)\n","W2 = 1 + (W1 + 2 * 2 - 5)\n","H3 = 1 + (H2 + 2 * 2*0 - 3)//3\n","W3 = 1 + (W2 + 2 * 2*0 - 3)//3\n","\n","H4 = 1 + (H3 + 2 * 1 - 3)\n","W4 = 1 + (W3 + 2 * 1 - 3)\n","H5 = 1 + (H4 + 2 * 1 - 3)\n","W5 = 1 + (W4 + 2 * 1 - 3)\n","H6 = 1 + (H5 + 2 * 2*0 - 3)//3\n","W6 = 1 + (W5 + 2 * 2*0 - 3)//3\n","\n","\n","rotation_net = nn.Sequential(nn.BatchNorm2d(3),nn.ReLU(),nn.Conv2d(3,channel_1,5,padding = 2),\n","                      nn.BatchNorm2d(channel_1),nn.ReLU(),nn.Conv2d(channel_1,channel_2,5,padding = 2),\n","                      nn.BatchNorm2d(channel_2), nn.ReLU(),nn.MaxPool2d(3),\n","                      nn.BatchNorm2d(channel_2),nn.ReLU(),nn.Conv2d(channel_2,channel_4,3,padding = 1),\n","                      nn.BatchNorm2d(channel_4),nn.ReLU(),nn.Conv2d(channel_4,channel_5,3,padding = 1),\n","                      Flatten(),nn.Linear(channel_5*H5*W5, hidden_layer_size),\n","                      nn.Linear(hidden_layer_size, num_classes))\n","\n","# rotation_net = models.efficientnet_b0(pretrained=False,num_classes = num_classes)\n","\n","load_model = True\n","if load_model:\n","  rotation_net.load_state_dict(torch.load(\"./rotnet_small_73.pth\"))\n","\n","for param in rotation_net.parameters():\n","    param.requires_grad = False\n","\n","\n","rotation_net[17] = nn.Linear(hidden_layer_size,num_classes_downstream)\n","\n","if torch.cuda.is_available():\n","    rotation_net.cuda()"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"89uam_0ZorsN","executionInfo":{"status":"ok","timestamp":1650468605755,"user_tz":240,"elapsed":332,"user":{"displayName":"Joseph Daniel Selvaraaj","userId":"01267249207347429283"}}},"outputs":[],"source":["learning_rate = 4e-5\n","momentum = 0.9\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer = optim.RMSprop(rotation_net.parameters(), lr=learning_rate,momentum=momentum)\n","\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xvN2T6KSorvf","executionInfo":{"status":"ok","timestamp":1650468778076,"user_tz":240,"elapsed":172021,"user":{"displayName":"Joseph Daniel Selvaraaj","userId":"01267249207347429283"}},"outputId":"4e1cae88-4217-4d98-babd-44c08abbf84d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 1.6123\n","Checking accuracy on validation set\n","Got 444 / 1000 correct (44.40)\n","\n","Iteration 100, loss = 1.4486\n","Checking accuracy on validation set\n","Got 450 / 1000 correct (45.00)\n","\n","Iteration 200, loss = 1.6973\n","Checking accuracy on validation set\n","Got 449 / 1000 correct (44.90)\n","\n","Iteration 300, loss = 1.5895\n","Checking accuracy on validation set\n","Got 450 / 1000 correct (45.00)\n","\n","Iteration 400, loss = 1.6070\n","Checking accuracy on validation set\n","Got 458 / 1000 correct (45.80)\n","\n","Iteration 500, loss = 1.7813\n","Checking accuracy on validation set\n","Got 454 / 1000 correct (45.40)\n","\n","Iteration 600, loss = 1.6526\n","Checking accuracy on validation set\n","Got 447 / 1000 correct (44.70)\n","\n","Iteration 700, loss = 1.3796\n","Checking accuracy on validation set\n","Got 450 / 1000 correct (45.00)\n","\n","Iteration 0, loss = 1.4561\n","Checking accuracy on validation set\n","Got 455 / 1000 correct (45.50)\n","\n","Iteration 100, loss = 1.5089\n","Checking accuracy on validation set\n","Got 440 / 1000 correct (44.00)\n","\n","Iteration 200, loss = 1.6785\n","Checking accuracy on validation set\n","Got 456 / 1000 correct (45.60)\n","\n","Iteration 300, loss = 1.5332\n","Checking accuracy on validation set\n","Got 450 / 1000 correct (45.00)\n","\n","Iteration 400, loss = 1.6092\n","Checking accuracy on validation set\n","Got 451 / 1000 correct (45.10)\n","\n","Iteration 500, loss = 1.5442\n","Checking accuracy on validation set\n","Got 451 / 1000 correct (45.10)\n","\n","Iteration 600, loss = 1.6344\n","Checking accuracy on validation set\n","Got 460 / 1000 correct (46.00)\n","\n","Iteration 700, loss = 1.3819\n","Checking accuracy on validation set\n","Got 457 / 1000 correct (45.70)\n","\n","Iteration 0, loss = 1.5052\n","Checking accuracy on validation set\n","Got 447 / 1000 correct (44.70)\n","\n","Iteration 100, loss = 1.5435\n","Checking accuracy on validation set\n","Got 456 / 1000 correct (45.60)\n","\n","Iteration 200, loss = 1.5538\n","Checking accuracy on validation set\n","Got 455 / 1000 correct (45.50)\n","\n","Iteration 300, loss = 1.4840\n","Checking accuracy on validation set\n","Got 454 / 1000 correct (45.40)\n","\n","Iteration 400, loss = 1.7177\n","Checking accuracy on validation set\n","Got 454 / 1000 correct (45.40)\n","\n","Iteration 500, loss = 1.4579\n","Checking accuracy on validation set\n","Got 463 / 1000 correct (46.30)\n","\n","Iteration 600, loss = 1.5290\n","Checking accuracy on validation set\n","Got 454 / 1000 correct (45.40)\n","\n","Iteration 700, loss = 1.6100\n","Checking accuracy on validation set\n","Got 453 / 1000 correct (45.30)\n","\n","Iteration 0, loss = 1.6065\n","Checking accuracy on validation set\n","Got 450 / 1000 correct (45.00)\n","\n","Iteration 100, loss = 1.4291\n","Checking accuracy on validation set\n","Got 448 / 1000 correct (44.80)\n","\n","Iteration 200, loss = 1.5869\n","Checking accuracy on validation set\n","Got 450 / 1000 correct (45.00)\n","\n","Iteration 300, loss = 1.5662\n","Checking accuracy on validation set\n","Got 457 / 1000 correct (45.70)\n","\n","Iteration 400, loss = 1.4176\n","Checking accuracy on validation set\n","Got 458 / 1000 correct (45.80)\n","\n","Iteration 500, loss = 1.6670\n","Checking accuracy on validation set\n","Got 457 / 1000 correct (45.70)\n","\n","Iteration 600, loss = 1.6737\n","Checking accuracy on validation set\n","Got 452 / 1000 correct (45.20)\n","\n","Iteration 700, loss = 1.4776\n","Checking accuracy on validation set\n","Got 455 / 1000 correct (45.50)\n","\n","Iteration 0, loss = 1.3864\n","Checking accuracy on validation set\n","Got 461 / 1000 correct (46.10)\n","\n","Iteration 100, loss = 1.7169\n","Checking accuracy on validation set\n","Got 444 / 1000 correct (44.40)\n","\n","Iteration 200, loss = 1.4619\n","Checking accuracy on validation set\n","Got 453 / 1000 correct (45.30)\n","\n","Iteration 300, loss = 1.5097\n","Checking accuracy on validation set\n","Got 457 / 1000 correct (45.70)\n","\n","Iteration 400, loss = 1.6060\n","Checking accuracy on validation set\n","Got 453 / 1000 correct (45.30)\n","\n","Iteration 500, loss = 1.6090\n","Checking accuracy on validation set\n","Got 446 / 1000 correct (44.60)\n","\n","Iteration 600, loss = 1.7600\n","Checking accuracy on validation set\n","Got 459 / 1000 correct (45.90)\n","\n","Iteration 700, loss = 1.4111\n","Checking accuracy on validation set\n","Got 459 / 1000 correct (45.90)\n","\n","Iteration 0, loss = 1.7306\n","Checking accuracy on validation set\n","Got 459 / 1000 correct (45.90)\n","\n","Iteration 100, loss = 1.4669\n","Checking accuracy on validation set\n","Got 458 / 1000 correct (45.80)\n","\n","Iteration 200, loss = 1.7720\n","Checking accuracy on validation set\n","Got 457 / 1000 correct (45.70)\n","\n","Iteration 300, loss = 1.4276\n","Checking accuracy on validation set\n","Got 457 / 1000 correct (45.70)\n","\n","Iteration 400, loss = 1.4586\n","Checking accuracy on validation set\n","Got 467 / 1000 correct (46.70)\n","\n","Iteration 500, loss = 1.5322\n","Checking accuracy on validation set\n","Got 463 / 1000 correct (46.30)\n","\n","Iteration 600, loss = 1.5946\n","Checking accuracy on validation set\n","Got 448 / 1000 correct (44.80)\n","\n","Iteration 700, loss = 1.5483\n","Checking accuracy on validation set\n","Got 451 / 1000 correct (45.10)\n","\n","Iteration 0, loss = 1.5621\n","Checking accuracy on validation set\n","Got 444 / 1000 correct (44.40)\n","\n","Iteration 100, loss = 1.4495\n","Checking accuracy on validation set\n","Got 457 / 1000 correct (45.70)\n","\n","Iteration 200, loss = 1.4402\n","Checking accuracy on validation set\n","Got 458 / 1000 correct (45.80)\n","\n","Iteration 300, loss = 1.5888\n","Checking accuracy on validation set\n","Got 464 / 1000 correct (46.40)\n","\n","Iteration 400, loss = 1.6839\n","Checking accuracy on validation set\n","Got 454 / 1000 correct (45.40)\n","\n","Iteration 500, loss = 1.4053\n","Checking accuracy on validation set\n","Got 452 / 1000 correct (45.20)\n","\n","Iteration 600, loss = 1.4902\n","Checking accuracy on validation set\n","Got 453 / 1000 correct (45.30)\n","\n","Iteration 700, loss = 1.6526\n","Checking accuracy on validation set\n","Got 454 / 1000 correct (45.40)\n","\n","Iteration 0, loss = 1.5803\n","Checking accuracy on validation set\n","Got 454 / 1000 correct (45.40)\n","\n","Iteration 100, loss = 1.5374\n","Checking accuracy on validation set\n","Got 456 / 1000 correct (45.60)\n","\n","Iteration 200, loss = 1.6122\n","Checking accuracy on validation set\n","Got 455 / 1000 correct (45.50)\n","\n","Iteration 300, loss = 1.5017\n","Checking accuracy on validation set\n","Got 460 / 1000 correct (46.00)\n","\n","Iteration 400, loss = 1.4602\n","Checking accuracy on validation set\n","Got 453 / 1000 correct (45.30)\n","\n","Iteration 500, loss = 1.5477\n","Checking accuracy on validation set\n","Got 456 / 1000 correct (45.60)\n","\n","Iteration 600, loss = 1.5335\n","Checking accuracy on validation set\n","Got 461 / 1000 correct (46.10)\n","\n","Iteration 700, loss = 1.4573\n","Checking accuracy on validation set\n","Got 459 / 1000 correct (45.90)\n","\n","Iteration 0, loss = 1.7890\n","Checking accuracy on validation set\n","Got 459 / 1000 correct (45.90)\n","\n","Iteration 100, loss = 1.3956\n","Checking accuracy on validation set\n","Got 451 / 1000 correct (45.10)\n","\n","Iteration 200, loss = 1.4882\n","Checking accuracy on validation set\n","Got 472 / 1000 correct (47.20)\n","\n","Iteration 300, loss = 1.3005\n","Checking accuracy on validation set\n","Got 455 / 1000 correct (45.50)\n","\n","Iteration 400, loss = 1.5244\n","Checking accuracy on validation set\n","Got 459 / 1000 correct (45.90)\n","\n","Iteration 500, loss = 1.5774\n","Checking accuracy on validation set\n","Got 461 / 1000 correct (46.10)\n","\n","Iteration 600, loss = 1.7511\n","Checking accuracy on validation set\n","Got 454 / 1000 correct (45.40)\n","\n","Iteration 700, loss = 1.4915\n","Checking accuracy on validation set\n","Got 452 / 1000 correct (45.20)\n","\n","Iteration 0, loss = 1.4818\n","Checking accuracy on validation set\n","Got 454 / 1000 correct (45.40)\n","\n","Iteration 100, loss = 1.4786\n","Checking accuracy on validation set\n","Got 457 / 1000 correct (45.70)\n","\n","Iteration 200, loss = 1.5946\n","Checking accuracy on validation set\n","Got 455 / 1000 correct (45.50)\n","\n","Iteration 300, loss = 1.4493\n","Checking accuracy on validation set\n","Got 455 / 1000 correct (45.50)\n","\n","Iteration 400, loss = 1.4290\n","Checking accuracy on validation set\n","Got 459 / 1000 correct (45.90)\n","\n","Iteration 500, loss = 1.4723\n","Checking accuracy on validation set\n","Got 458 / 1000 correct (45.80)\n","\n","Iteration 600, loss = 1.5034\n","Checking accuracy on validation set\n","Got 464 / 1000 correct (46.40)\n","\n","Iteration 700, loss = 1.5232\n","Checking accuracy on validation set\n","Got 459 / 1000 correct (45.90)\n","\n"]}],"source":["torch.cuda.empty_cache()\n","train_part34(rotation_net,optimizer, exp_lr_scheduler, \"./rotnet_downstream_small.pth\")"]},{"cell_type":"code","source":["check_accuracy_part34(dataloaders[\"test\"], rotation_net)"],"metadata":{"id":"oHUmEVYPMD0r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650468780759,"user_tz":240,"elapsed":2693,"user":{"displayName":"Joseph Daniel Selvaraaj","userId":"01267249207347429283"}},"outputId":"d1f3d086-ff14-42f0-fada-acf2106e8f22"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Checking accuracy on test set\n","Got 4585 / 10000 correct (45.85)\n"]},{"output_type":"execute_result","data":{"text/plain":["0.4585"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p0fWlB2ForxI"},"outputs":[],"source":["plt.subplot(2, 1, 1)\n","plt.plot(train_loss, '-o')\n","plt.plot(val_loss, '-o')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.show()\n","\n","train_acc = [x.cpu() for x in train_acc]\n","val_acc = [x.cpu() for x in val_acc]\n","\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(train_acc, '-o')\n","plt.plot(val_acc, '-o')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"RotNet_downstream_small.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}